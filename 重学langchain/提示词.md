> 这篇文章我们将会一起深入探索 LangChain PromptTemplate 组件，使用 PromptTemplate 是我们开发 LLM APP 的开始，现在，让我们开始吧！

# 什么是提示词（Prompt）

提示词（Prompts）是指提供给机器学习模型的初始文本，模型会基于这些文本生成新的自然语言文本。

我们可以简单的把提示词理解成是大语言模型的调用接口，我们通过提示词调用大语言模型的能力。

在写提示词中有很多的技巧需要掌握，如 COT、ReAct 等，完美的提示词是一个不断迭代的过程。想要了解更多，推荐学习 OpenAI 与吴恩达的推出的 《prompt engineering for developers》 课程。

# 提示词模版（PromptTemplate）

## 什么是提示词模版

PromptTemplate 是可重复生成 Prompt 的方案。如下面的 Javascript 例子：

```javascript
import { PromptTemplate } from "langchain/prompts";

const template = `
    把下面三联引号中的文本翻译成英语：
    """
    {input}
    """
    输出：
`
const prompt = new PromptTemplate({ template, inputVariables: ["input"] });

async function run() {
  const response = await prompt.format({ input: "今天天气很好" });
  console.log(response);
}

run()
/**
 
把下面三联引号中的文本翻译成英语：
"""
今天天气很好
"""
输出：

*/

```

这个例子中，我们通过 PromptTemplate 可以随时生成一个用于翻译的提示词，更好的封装与复用提示词。

## PromptTemplate 和编程中的模版引擎有什么区别？

他们的实现原理相同，Python 和 Javascript 版本中的 PromptTemplate 只支持 jinja2 和 f-string 格式的模版，如果需要更多的格式支持可以去官方仓库提交相关 issue。

PromptTemplate 除了解析模版数据，还加入了 Example Selectors，下面我们会介绍它们。

# 提示词选择器（Example Selectors）

在使用提示词选择器之前我们需要了解 LLM 中的 Few-shot 的概念。

Few-shot learning 目标是通过从有限数量的标记样本中学习到的一般化知识，来对新的类别进行学习和推断。

简单来说，LLM 有很强的推理能力，我们可以通过给它一些例子，让 LLM 通过这些少量的例子学习处理我们的任务。

如下面的例子，我们让 LLM 做一个反义词的游戏：
```
// 我们输入的提示词
单词: 幸福
反义词: 伤心
单词: 高
反义词: 矮
单词: 大
反义词:

// 大语言模型的输出
小
```
上面的示例中，我们通过一些小例子，成功让 LLM 输出了 大 的反义词 小。

现实场景中 Few-shot 的例子的数量是未知的，通常我们会准备很多，而 LLM 有 Token 数量的限制。通过 Example Selectors 可以帮助我们截取合适数量的例子，且***不会破坏例子的语义***，如下：
```js
import {
  LengthBasedExampleSelector,
  PromptTemplate,
  FewShotPromptTemplate,
} from "langchain/prompts";

export async function run() {
  const examplePrompt = new PromptTemplate({
    inputVariables: ["input", "output"],
    template: "输入: {input}\n输出: {output}",
  });

  // FewShot 的例子选择器
  const exampleSelector = await LengthBasedExampleSelector.fromExamples(
    [
      { input: "幸福", output: "伤心" },
      { input: "高", output: "矮" },
      { input: "精力充沛", output: "昏昏欲睡" },
      { input: "晴天", output: "阴天" },
      { input: "多风", output: "平静" },
    ],
    {
      examplePrompt,
      maxLength: 25, // 限制 Token 数量
    }
  );

  // 创建 FewShot 提示词模版
  const dynamicPrompt = new FewShotPromptTemplate({
    exampleSelector,
    examplePrompt,
    prefix: "生成每个输入的反义词",
    suffix: "输入: {adjective}\n输出:",
    inputVariables: ["adjective"],
  });

  console.log(await dynamicPrompt.format({ adjective: "大" }));
  /*
   生成每个输入的反义词

   输入: 幸福
   输出: 伤心

   输入: 高
   输出: 矮

   输入: 精力充沛
   输出: 昏昏欲睡

   输入: 晴天
   输出: 阴天

   输入: 多风
   输出: 平静

   输入: 大
   输出:
   */

  const longString =
    "巨大、庞大、大量、宽广、巨型、高大、比其他任何事物都要大得多得多得多得多得多";
  console.log(await dynamicPrompt.format({ adjective: longString }));
  /*
   生成每个输入的反义词

   输入: 幸福
   输出: 伤心

   输入: 巨大、庞大、大量、宽广、巨型、高大、比其他任何事物都要大得多得多得多得多得多
   输出:
   */
}
```

合理使用 ExampleSelector 让我们的 LLM App 工作更加稳定且节省 Token。

# 输出转换（OutputParser）

大语言模型像人类一样输出的自然语言，但在开发应用中我们经常需要结构化的数据，OutputParser 便可以把输出转换成结构化的数据，如下面 JSON 的例子：

```js
import { OpenAI } from "langchain/llms/openai";
import { PromptTemplate } from "langchain/prompts";
import { StructuredOutputParser } from "langchain/output_parsers";

// 使用 `StructuredOutputParser` 定义输出的格式与字段.
const parser = StructuredOutputParser.fromNamesAndDescriptions({
  answer: "回答用户的问题",
  source: "回答用到的引用资源网址",
});

const formatInstructions = parser.getFormatInstructions();

const prompt = new PromptTemplate({
  template:
    "尽你所能回答用户的问题。\n{format_instructions}\n{question}",
  inputVariables: ["question"],
  partialVariables: { format_instructions: formatInstructions },
});

const model = new OpenAI({ temperature: 0 });

const input = await prompt.format({
  question: "法国的首都在哪里？",
});
const response = await model.call(input);

console.log(input);

/**
 
尽你所能回答用户的问题。
You must format your output as a JSON value that adheres to a given "JSON Schema" instance.

"JSON Schema" is a declarative language that allows you to annotate and validate JSON documents.

For example, the example "JSON Schema" instance {{"properties": {{"foo": {{"description": "a list of test words", "type": "array", "items": {{"type": "string"}}}}}}, "required": ["foo"]}}}}
would match an object with one required property, "foo". The "type" property specifies "foo" must be an "array", and the "description" property semantically describes it as "a list of test words". The items within "foo" must be strings.
Thus, the object {{"foo": ["bar", "baz"]}} is a well-formatted instance of this example "JSON Schema". The object {{"properties": {{"foo": ["bar", "baz"]}}}} is not well-formatted.

Your output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match the schema exactly and there are no trailing commas!

Here is the JSON Schema instance your output must adhere to. Include the enclosing markdown codeblock:
``json
{"type":"object","properties":{"answer":{"type":"string","description":"回答用户的问题"},"source":{"type":"string","description":"回答用到的引用资源网址"}},"required":["answer","source"],"additionalProperties":false,"$schema":"http://json-schema.org/draft-07/schema#"}
``
法国的首都在哪里？

*/

console.log(response);
/*
{"answer": "巴黎", "source": "https://en.wikipedia.org/wiki/Paris"}
*/

// 转换成 JS 中的对象
console.log(await parser.parse(response));
// { answer: '巴黎', source: 'https://en.wikipedia.org/wiki/Paris' }
```


> 我们现在已经掌握了 LangChain 的 PromptTemplate 的部分，这是非常重要的一步。下一篇我们要一起探索解析器（Indexs），让 LLM 读懂物理世界的多样信息，我们下一篇见！
